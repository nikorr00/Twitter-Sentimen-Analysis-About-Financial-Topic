{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c869ddf3-68b1-4eea-a7ce-a8094df436cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     -------------------------------------- 636.8/636.8 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Requirement already satisfied: wordcloud in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from wordcloud) (1.21.5+mkl)\n",
      "Requirement already satisfied: pillow in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from wordcloud) (9.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (4.31.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\program files\\wpy64-31040\\python-3.10.4.amd64\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24dfa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cebc63d7-626c-4324-a398-2f83bbcac9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63e8fd0d-d6d6-4845-9c1a-20d5da05f925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_twitterfinansial.csv',sep=\";\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a33c6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created-At</th>\n",
       "      <th>From-User</th>\n",
       "      <th>From-User-Id</th>\n",
       "      <th>To-User</th>\n",
       "      <th>To-User-Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Text</th>\n",
       "      <th>Geo-Location-Latitude</th>\n",
       "      <th>Geo-Location-Longitude</th>\n",
       "      <th>Retweet-Count</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20/08/2022 11:10</td>\n",
       "      <td>Minor League Baseball</td>\n",
       "      <td>34363347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>17-RUN INNING!\\n\\nThe Triple-A @astros affilia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20/08/2022 08:41</td>\n",
       "      <td>Ebony Elizabeth Thomas</td>\n",
       "      <td>322742783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>Ambassador @WBStevens, as an SWFA affiliate me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20/08/2022 02:50</td>\n",
       "      <td>The Circuit</td>\n",
       "      <td>1342662080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>The Circuit's 3SSB Coach of the Year: pres. by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20/08/2022 21:03</td>\n",
       "      <td>A Deal Sharing Community</td>\n",
       "      <td>3881432236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://app.socialpilot.co/' rel='nof...</td>\n",
       "      <td>?Multiuse Code?\\n50%OFF\\nCode: 50VNXFXO\\n?Let ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20/08/2022 21:03</td>\n",
       "      <td>COMMISSIONS OPEN WOO -saben/binx</td>\n",
       "      <td>1,31E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/iphone' r...</td>\n",
       "      <td>STREAMING TONIGHT!\\nfirst stream as affiliate!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>Amit (Taylor's version)</td>\n",
       "      <td>1,52E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>RT @aneetta_joby_: Money saving hack: Live wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>BPBT</td>\n",
       "      <td>1,35E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>th</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>RT @Koonkonrak: ???????? ??????????? ????????\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>LISA?</td>\n",
       "      <td>1,49E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>RT @chynxxxxx: This lisa is very sexc\\n\\nFEEL ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>KIRWEZOGA</td>\n",
       "      <td>577753527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>RT @ChuksDan: @atiku I think, by way of punish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>Business Money</td>\n",
       "      <td>217085795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>Impact Specialist Finance launch limited distr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3181 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Created-At                         From-User From-User-Id To-User  \\\n",
       "0     20/08/2022 11:10             Minor League Baseball     34363347     NaN   \n",
       "1     20/08/2022 08:41            Ebony Elizabeth Thomas    322742783     NaN   \n",
       "2     20/08/2022 02:50                       The Circuit   1342662080     NaN   \n",
       "3     20/08/2022 21:03          A Deal Sharing Community   3881432236     NaN   \n",
       "4     20/08/2022 21:03  COMMISSIONS OPEN WOO -saben/binx     1,31E+18     NaN   \n",
       "...                ...                               ...          ...     ...   \n",
       "3176  19/08/2022 15:10           Amit (Taylor's version)     1,52E+18     NaN   \n",
       "3177  19/08/2022 15:10                              BPBT     1,35E+18     NaN   \n",
       "3178  19/08/2022 15:10                             LISA?     1,49E+18     NaN   \n",
       "3179  19/08/2022 15:10                         KIRWEZOGA    577753527     NaN   \n",
       "3180  19/08/2022 15:10                    Business Money    217085795     NaN   \n",
       "\n",
       "     To-User-Id Language                                             Source  \\\n",
       "0            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "1            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "2            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "3            -1       en  <a href='https://app.socialpilot.co/' rel='nof...   \n",
       "4            -1       en  <a href='http://twitter.com/download/iphone' r...   \n",
       "...         ...      ...                                                ...   \n",
       "3176         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3177         -1       th  <a href='http://twitter.com/download/android' ...   \n",
       "3178         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3179         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3180         -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     17-RUN INNING!\\n\\nThe Triple-A @astros affilia...   \n",
       "1     Ambassador @WBStevens, as an SWFA affiliate me...   \n",
       "2     The Circuit's 3SSB Coach of the Year: pres. by...   \n",
       "3     ?Multiuse Code?\\n50%OFF\\nCode: 50VNXFXO\\n?Let ...   \n",
       "4     STREAMING TONIGHT!\\nfirst stream as affiliate!...   \n",
       "...                                                 ...   \n",
       "3176  RT @aneetta_joby_: Money saving hack: Live wit...   \n",
       "3177  RT @Koonkonrak: ???????? ??????????? ????????\\...   \n",
       "3178  RT @chynxxxxx: This lisa is very sexc\\n\\nFEEL ...   \n",
       "3179  RT @ChuksDan: @atiku I think, by way of punish...   \n",
       "3180  Impact Specialist Finance launch limited distr...   \n",
       "\n",
       "      Geo-Location-Latitude  Geo-Location-Longitude  Retweet-Count        Id  \n",
       "0                       NaN                     NaN            311  1,56E+18  \n",
       "1                       NaN                     NaN             71  1,56E+18  \n",
       "2                       NaN                     NaN             37  1,56E+18  \n",
       "3                       NaN                     NaN              0  1,56E+18  \n",
       "4                       NaN                     NaN              0  1,56E+18  \n",
       "...                     ...                     ...            ...       ...  \n",
       "3176                    NaN                     NaN            113  1,56E+18  \n",
       "3177                    NaN                     NaN            267  1,56E+18  \n",
       "3178                    NaN                     NaN             66  1,56E+18  \n",
       "3179                    NaN                     NaN              2  1,56E+18  \n",
       "3180                    NaN                     NaN              0  1,56E+18  \n",
       "\n",
       "[3181 rows x 12 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2b5be78-9c1d-46e5-b976-3734f6307df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>17-RUN INNING!\\n\\nThe Triple-A @astros affilia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>Ambassador @WBStevens, as an SWFA affiliate me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>The Circuit's 3SSB Coach of the Year: pres. by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>?Multiuse Code?\\n50%OFF\\nCode: 50VNXFXO\\n?Let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>STREAMING TONIGHT!\\nfirst stream as affiliate!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>RT @aneetta_joby_: Money saving hack: Live wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>RT @Koonkonrak: ???????? ??????????? ????????\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>RT @chynxxxxx: This lisa is very sexc\\n\\nFEEL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>RT @ChuksDan: @atiku I think, by way of punish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>Impact Specialist Finance launch limited distr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                               Text\n",
       "0     1,56E+18  17-RUN INNING!\\n\\nThe Triple-A @astros affilia...\n",
       "1     1,56E+18  Ambassador @WBStevens, as an SWFA affiliate me...\n",
       "2     1,56E+18  The Circuit's 3SSB Coach of the Year: pres. by...\n",
       "3     1,56E+18  ?Multiuse Code?\\n50%OFF\\nCode: 50VNXFXO\\n?Let ...\n",
       "4     1,56E+18  STREAMING TONIGHT!\\nfirst stream as affiliate!...\n",
       "...        ...                                                ...\n",
       "3176  1,56E+18  RT @aneetta_joby_: Money saving hack: Live wit...\n",
       "3177  1,56E+18  RT @Koonkonrak: ???????? ??????????? ????????\\...\n",
       "3178  1,56E+18  RT @chynxxxxx: This lisa is very sexc\\n\\nFEEL ...\n",
       "3179  1,56E+18  RT @ChuksDan: @atiku I think, by way of punish...\n",
       "3180  1,56E+18  Impact Specialist Finance launch limited distr...\n",
       "\n",
       "[3181 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['Id','Text']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5306a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "0    17-run inning!\\n\\nthe triple-a @astros affilia...\n",
      "1    ambassador @wbstevens, as an swfa affiliate me...\n",
      "2    the circuit's 3ssb coach of the year: pres. by...\n",
      "3    ?multiuse code?\\n50%off\\ncode: 50vnxfxo\\n?let ...\n",
      "4    streaming tonight!\\nfirst stream as affiliate!...\n",
      "Name: Text, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\1141292331.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "#--------Case Folding--------\n",
    "df2['Text'] = df2['Text'].str.lower()\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(df2['Text'].head(5))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f87d6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NIKORAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_tweet_special)\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_number)\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_punctuation)\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_whitespace_LT)\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_whitespace_multiple)\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text'] = df2['Text'].apply(remove_singl_char)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "0    []\n",
      "1    []\n",
      "2    []\n",
      "3    []\n",
      "4    []\n",
      "5    []\n",
      "6    []\n",
      "7    []\n",
      "8    []\n",
      "9    []\n",
      "Name: Text_tokens, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\3623354553.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text_tokens'] = df2['Text'].apply(word_tokenize_wrapper)\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re #regex library\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# import word_tokenize & FreqDist from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# ------ Tokenizing & Cleansing  ---------\n",
    "\n",
    "def remove_tweet_special(text):\n",
    "    # remove tab, new line, ans back slice\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    # remove rt sebagai retweet\n",
    "    text = text.replace(\"re\", \"\").strip()\n",
    "    # remove incomplete URL\n",
    "                \n",
    "df2['Text'] = df2['Text'].apply(remove_tweet_special)\n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text or '') #1\n",
    "\n",
    "df2['Text'] = df2['Text'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "df2['Text'] = df2['Text'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "df2['Text'] = df2['Text'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "df2['Text'] = df2['Text'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text or '') #2\n",
    "\n",
    "df2['Text'] = df2['Text'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word rokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df2['Text_tokens'] = df2['Text'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(df2['Text_tokens'].head(10))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e3cf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming Data\n",
    "ps = PorterStemmer() \n",
    "\n",
    "def stemming_data(x):\n",
    "    return ps.stem(x)\n",
    "\n",
    "df['Text'] = df['Text'].apply(stemming_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f079d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "0    []\n",
      "1    []\n",
      "2    []\n",
      "3    []\n",
      "4    []\n",
      "Name: Text_tokens_WSW, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NIKORAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\2087300649.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text_tokens_WSW'] = df2['Text_tokens'].apply(stopwords_removal)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
    "# get stopword english\n",
    "list_stopwords = stopwords.words('english')\n",
    "print(len(list_stopwords))\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "df2['Text_tokens_WSW'] = df2['Text_tokens'].apply(stopwords_removal) \n",
    "\n",
    "print(df2['Text_tokens_WSW'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00ff2455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Tokens : \n",
      "\n",
      "0    []\n",
      "1    []\n",
      "2    []\n",
      "3    []\n",
      "4    []\n",
      "5    []\n",
      "6    []\n",
      "7    []\n",
      "8    []\n",
      "9    []\n",
      "Name: Text_tokens_fdist, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIKORAM\\AppData\\Local\\Temp\\ipykernel_10208\\2633044772.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text_tokens_fdist'] = df2['Text_tokens'].apply(freqDist_wrapper)\n"
     ]
    }
   ],
   "source": [
    "# NLTK calc frequency distribution\n",
    "def freqDist_wrapper(text):\n",
    "    return FreqDist(text)\n",
    "\n",
    "\n",
    "df2['Text_tokens_fdist'] = df2['Text_tokens'].apply(freqDist_wrapper)\n",
    "\n",
    "print('Frequency Tokens : \\n') \n",
    "print(df2['Text_tokens_fdist'].head(10).apply(lambda x : x.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b0f4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Analisis Data:\n",
      "Positif = 1051\n",
      "Netral = 1641\n",
      "Negatif = 489\n",
      "\n",
      "Total Data : 3181\n"
     ]
    }
   ],
   "source": [
    "dataset = list(df['Text'])\n",
    "polaritas = 0\n",
    "\n",
    "status = []\n",
    "total_positif = total_negatif = total_netral = total = 0\n",
    "\n",
    "for i, tweet in enumerate(dataset):\n",
    "    analysis = TextBlob(tweet)\n",
    "    polaritas += analysis.polarity\n",
    "\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        total_positif += 1\n",
    "        status.append('positive')\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        total_netral += 1\n",
    "        status.append('neutral')\n",
    "    else:\n",
    "        total_negatif += 1\n",
    "        status.append('negative')\n",
    "\n",
    "    total += 1 \n",
    "    \n",
    "print(f'Hasil Analisis Data:\\nPositif = {total_positif}\\nNetral = {total_netral}\\nNegatif = {total_negatif}')\n",
    "print(f'\\nTotal Data : {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fd58d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created-At</th>\n",
       "      <th>From-User</th>\n",
       "      <th>From-User-Id</th>\n",
       "      <th>To-User</th>\n",
       "      <th>To-User-Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Text</th>\n",
       "      <th>Geo-Location-Latitude</th>\n",
       "      <th>Geo-Location-Longitude</th>\n",
       "      <th>Retweet-Count</th>\n",
       "      <th>Id</th>\n",
       "      <th>klasifikasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20/08/2022 11:10</td>\n",
       "      <td>Minor League Baseball</td>\n",
       "      <td>34363347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>17-run inning!\\n\\nthe triple-a @astros affilia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20/08/2022 08:41</td>\n",
       "      <td>Ebony Elizabeth Thomas</td>\n",
       "      <td>322742783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>ambassador @wbstevens, as an swfa affiliate me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20/08/2022 02:50</td>\n",
       "      <td>The Circuit</td>\n",
       "      <td>1342662080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>the circuit's 3ssb coach of the year: pres. by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20/08/2022 21:03</td>\n",
       "      <td>A Deal Sharing Community</td>\n",
       "      <td>3881432236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://app.socialpilot.co/' rel='nof...</td>\n",
       "      <td>?multiuse code?\\n50%off\\ncode: 50vnxfxo\\n?let ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20/08/2022 21:03</td>\n",
       "      <td>COMMISSIONS OPEN WOO -saben/binx</td>\n",
       "      <td>1,31E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/iphone' r...</td>\n",
       "      <td>streaming tonight!\\nfirst stream as affiliate!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>Amit (Taylor's version)</td>\n",
       "      <td>1,52E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>rt @aneetta_joby_: money saving hack: live wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>BPBT</td>\n",
       "      <td>1,35E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>th</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>rt @koonkonrak: ???????? ??????????? ????????\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>LISA?</td>\n",
       "      <td>1,49E+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>rt @chynxxxxx: this lisa is very sexc\\n\\nfeel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>KIRWEZOGA</td>\n",
       "      <td>577753527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='http://twitter.com/download/android' ...</td>\n",
       "      <td>rt @chuksdan: @atiku i think, by way of punish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>19/08/2022 15:10</td>\n",
       "      <td>Business Money</td>\n",
       "      <td>217085795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href='https://mobile.twitter.com' rel='nofo...</td>\n",
       "      <td>impact specialist finance launch limited distr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3181 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Created-At                         From-User From-User-Id To-User  \\\n",
       "0     20/08/2022 11:10             Minor League Baseball     34363347     NaN   \n",
       "1     20/08/2022 08:41            Ebony Elizabeth Thomas    322742783     NaN   \n",
       "2     20/08/2022 02:50                       The Circuit   1342662080     NaN   \n",
       "3     20/08/2022 21:03          A Deal Sharing Community   3881432236     NaN   \n",
       "4     20/08/2022 21:03  COMMISSIONS OPEN WOO -saben/binx     1,31E+18     NaN   \n",
       "...                ...                               ...          ...     ...   \n",
       "3176  19/08/2022 15:10           Amit (Taylor's version)     1,52E+18     NaN   \n",
       "3177  19/08/2022 15:10                              BPBT     1,35E+18     NaN   \n",
       "3178  19/08/2022 15:10                             LISA?     1,49E+18     NaN   \n",
       "3179  19/08/2022 15:10                         KIRWEZOGA    577753527     NaN   \n",
       "3180  19/08/2022 15:10                    Business Money    217085795     NaN   \n",
       "\n",
       "     To-User-Id Language                                             Source  \\\n",
       "0            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "1            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "2            -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "3            -1       en  <a href='https://app.socialpilot.co/' rel='nof...   \n",
       "4            -1       en  <a href='http://twitter.com/download/iphone' r...   \n",
       "...         ...      ...                                                ...   \n",
       "3176         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3177         -1       th  <a href='http://twitter.com/download/android' ...   \n",
       "3178         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3179         -1       en  <a href='http://twitter.com/download/android' ...   \n",
       "3180         -1       en  <a href='https://mobile.twitter.com' rel='nofo...   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     17-run inning!\\n\\nthe triple-a @astros affilia...   \n",
       "1     ambassador @wbstevens, as an swfa affiliate me...   \n",
       "2     the circuit's 3ssb coach of the year: pres. by...   \n",
       "3     ?multiuse code?\\n50%off\\ncode: 50vnxfxo\\n?let ...   \n",
       "4     streaming tonight!\\nfirst stream as affiliate!...   \n",
       "...                                                 ...   \n",
       "3176  rt @aneetta_joby_: money saving hack: live wit...   \n",
       "3177  rt @koonkonrak: ???????? ??????????? ????????\\...   \n",
       "3178  rt @chynxxxxx: this lisa is very sexc\\n\\nfeel ...   \n",
       "3179  rt @chuksdan: @atiku i think, by way of punish...   \n",
       "3180  impact specialist finance launch limited distr...   \n",
       "\n",
       "      Geo-Location-Latitude  Geo-Location-Longitude  Retweet-Count        Id  \\\n",
       "0                       NaN                     NaN            311  1,56E+18   \n",
       "1                       NaN                     NaN             71  1,56E+18   \n",
       "2                       NaN                     NaN             37  1,56E+18   \n",
       "3                       NaN                     NaN              0  1,56E+18   \n",
       "4                       NaN                     NaN              0  1,56E+18   \n",
       "...                     ...                     ...            ...       ...   \n",
       "3176                    NaN                     NaN            113  1,56E+18   \n",
       "3177                    NaN                     NaN            267  1,56E+18   \n",
       "3178                    NaN                     NaN             66  1,56E+18   \n",
       "3179                    NaN                     NaN              2  1,56E+18   \n",
       "3180                    NaN                     NaN              0  1,56E+18   \n",
       "\n",
       "     klasifikasi  \n",
       "0        neutral  \n",
       "1       positive  \n",
       "2       positive  \n",
       "3        neutral  \n",
       "4       positive  \n",
       "...          ...  \n",
       "3176    positive  \n",
       "3177     neutral  \n",
       "3178    positive  \n",
       "3179    positive  \n",
       "3180    negative  \n",
       "\n",
       "[3181 rows x 13 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = pd.DataFrame({'klasifikasi': status})\n",
    "df['klasifikasi'] = status\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e324008b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Text_tokens', 'Text_tokens_fdist', 'Text_tokens_WSW'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10208\\3368468195.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'klasifikasi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Text_tokens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Text_tokens_fdist'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Text_tokens_WSW'\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WPy64-31040\\python-3.10.4.amd64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WPy64-31040\\python-3.10.4.amd64\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5782\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WPy64-31040\\python-3.10.4.amd64\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5845\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5847\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Text_tokens', 'Text_tokens_fdist', 'Text_tokens_WSW'] not in index\""
     ]
    }
   ],
   "source": [
    "df2=df[['Id','Text','klasifikasi','Text_tokens', 'Text_tokens_fdist','Text_tokens_WSW' ]]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e58acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pie(label, data, legend_title) :\n",
    "    fig, ax = plt.subplots(figsize=(8, 10), subplot_kw=dict(aspect='equal'))\n",
    "\n",
    "    labels = [x.split()[-1] for x in label]\n",
    "\n",
    "    def func(pct, allvals):\n",
    "        absolute = int(pct/100.*np.sum(allvals))\n",
    "        return \"{:.1f}% ({:d})\".format(pct, absolute)\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data), \n",
    "                                      textprops=dict(color=\"w\"))\n",
    "\n",
    "    ax.legend(wedges, labels,\n",
    "              title= legend_title,\n",
    "              loc=\"center left\",\n",
    "              bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "    plt.setp(autotexts, size=10, weight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['positive', 'negative',]\n",
    "count_data = [total_positif+1, total_negatif+1,]\n",
    "\n",
    "show_pie(label, count_data, \"TextBlob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87833c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([tweets for tweets in df['Text']])\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=3, background_color='white', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(all_words)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Data_Klasifikasi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449af7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Data_Klasifikasi.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
